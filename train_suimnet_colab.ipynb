{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c5d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: GPU check and Drive mount\n",
    "import torch\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18458a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/emanusilva2003/Assignment_2_ComputerVision\n",
    "\n",
    "import sys\n",
    "repo_path = '/content/Assignment_2_ComputerVision'\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)\n",
    "print(f'Repo path: {repo_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from SUIM.Pytorch.models.suim_net import SUIM_Net\n",
    "from SUIM.Pytorch.utils.data_utils import get_suim_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bdfcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE = 'RSB'  # 'VGG' or 'RSB'\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Paths (ajusta o caminho do Drive para o teu dataset)\n",
    "TRAIN_DIR = '/content/drive/MyDrive/VCOM/SUIM/train_val'\n",
    "CKPT_DIR = '/content/drive/MyDrive/VCOM/checkpoints'\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"{BASE} | Batch: {BATCH_SIZE} | Epochs: {NUM_EPOCHS} | Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba70fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and Model\n",
    "train_loader = get_suim_dataloader(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(320, 256),\n",
    "    augmentation=True,\n",
    "    augmentation_params={'rotation_range': 0.2, 'width_shift_range': 0.05,\n",
    "                        'height_shift_range': 0.05, 'shear_range': 0.05,\n",
    "                        'zoom_range': 0.05, 'horizontal_flip': True},\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "model = SUIM_Net(base=BASE, n_classes=5, pretrained=True).to(DEVICE)\n",
    "total, trainable = model.count_parameters()\n",
    "print(f\"Samples: {len(train_loader.dataset)} | Params: {total:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bce876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "history = {'loss': [], 'lr': []}\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    for images, masks in pbar:\n",
    "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    history['loss'].append(avg_loss)\n",
    "    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f} | LR: {history['lr'][-1]:.2e}\")\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Save best\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': best_loss,\n",
    "        }, os.path.join(CKPT_DIR, f\"suimnet_{BASE.lower()}_best.pth\"))\n",
    "        print(f\"  ✓ Best: {best_loss:.4f}\")\n",
    "    \n",
    "    # Checkpoint every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, os.path.join(CKPT_DIR, f\"suimnet_{BASE.lower()}_epoch_{epoch+1}.pth\"))\n",
    "        print(f\"  ✓ Checkpoint saved\")\n",
    "\n",
    "print(f\"\\nCompleted! Best loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history['loss'], 'b-', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.plot(history['lr'], 'r-', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Learning Rate')\n",
    "ax2.set_title('LR Schedule')\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial: {history['loss'][0]:.4f} | Final: {history['loss'][-1]:.4f} | Best: {best_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
